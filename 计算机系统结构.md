<h1 align="center"> 计算机系统结构</h1>

# 第一章基础知识

> 系统结构的相关概念
>
> - 计算机系统层次结构
> - 计算机系统结构基本概念（广义机器、透明性、编译）
> - 计算机系统结构、组织、实现的定义
> - 计算机系统分类方法/Flynn 分类法
>
> 基本原理和性能公式
>
> - 大概率事件优先
> - Amdahl 定律
> - 程序的局部性原理
> - CPU 性能计算
> - <u>加速比公式应用</u>
>
> 性能评价标准
>
> - <u>性能指标</u>（CPU 时间、<u>CPI</u>、MIPS、MFLOPS）

## 计算机系统结构相关概念

计算机系统的层次结构：计算机是由硬件、软件、固件（固化的微程序）组成的复杂系统，按机器语言功能划分为多级层次结构。

下面两级（微程序级、传统机器语言机器级）使用硬件/固件实现，称为<u>物理机</u>。上面四级由软件实现，称为<u>虚拟机</u>。第二级（传统机器语言级）是软硬件界面。

| 层数 | 语言             | 实现                                                   |
| ---- | ---------------- | ------------------------------------------------------ |
| 0    | 布尔语言（硬件） |                                                        |
| 1    | 微程序指令       | 用微指令集编写微程序，固件、硬件来解释                 |
| 2    | 传统机器语言     | 传统机器语言程序有 L1 级微程序或 L0 级硬联逻辑进行解释 |
| 3    | 操作系统         | 包括传统机器及操作系统级指令，由微程序解释             |
| 4    | 汇编语言         | 翻译成 L3 和 L2 级语言执行                             |
| 5    | 高级语言         | 通过编译程序翻译到 L4 或 L3 级，或通过解释方法实现     |
| 6    | 应用语言         | 由应用程序包翻译到 L5                                  |

翻译和解释：一般情况，上述六级层次的 L1-L3 用解释实现，而 L4-L6 用翻译实现。

- 翻译：用转换程序把高一级机器上的程序转换为低一级机器上的等效程序，然后再在这低一级机器上运行。速度快、占用空间大。
- 解释：对于高一级机器上程序中的每一条语句或指令，转换为低级语言的一段等效程序执行，执行完后再去高一级机器取下一条语句或指令。速度慢、占用空间小。

计算机系统结构的定义：

- 计算机系统结构是指传统机器程序员所看到的计算机属性，即概念性结构与功能特性。
- 计算机系统结构的实质：<u>确定计算机系统中软硬件的界面</u>，界面之上是软件实现的功能，界面之下是硬件和固件实现的功能。
- <u>透明性</u>：一种本来存在的事物或属性，从某种角度看好像不存在或看不到。低层机器的属性对高层机器程序员来说通常是透明的。
- <u>广义系统结构定义</u>：包括指令系统结构、组成、硬件。

计算机系统结构、组成、实现：

- <u>计算机体系结构</u>：数据表示、寻址规则、寄存器定义、指令集、终端系统、机器工作状态的定义和切换、存储体系、信息保护、I/O 结构等。

- <u>计算机组成</u>：计算机系统结构的逻辑实现，包含物理机器级中的数据流和控制流的组成以及逻辑设计等。着眼于：物理机器级内各事件的排序方式与控制方式、各部件的功能以及各部件之间的联系。<u>具有相同系统结构的计算机可以采用不同的计算机组成。</u>

- <u>计算机实现</u>：计算机组成的物理实现。着眼于：器件技术、微组装技术。<u>同一种计算机组成又可以采用多种不同的计算机实现。</u>

  > 例：
  >
  > - 机器指令集的确定、主存容量与编址方式等属于计算机体系结构。
  > - 指令实现方式（取指令、去操作数、运算、送结果等的具体操作及排序方式）、主存速度与逻辑结构（多体交叉存储）等属于计算机组织（计算机组成）。
  > - 实现指令集中所有指令功能的具体电路、器件的设计、装配技术，存储器器件和逻辑电路的设计等属于计算机实现。

计算机系统分类方法/Flynn 分类法：

- Flynn 分类法：按照指令流和数据流的多倍性分类。

  - 指令流：计算机执行的指令序列
  - 数据流：由指令流调用的数据序列
  - 多倍性：在系统**最受限**的部件上，同时处于统一执行阶段的指令或数据的最大数目

  分为 SISD（传统顺序处理计算机）、SIMD（阵列处理机）、MISD（不存在）、MIMD（多处理机）系统。

  <img src="计算机系统结构.assets/image-20210615211604807.png" alt="image-20210615211604807" style="zoom:50%;" />

- Handler 分类法：把硬件结构分为三个层次，根据并行度和流水线分类。

  $T=<k\times k', d \times d', w \times w'>$

  k：控制器数目，k'：控制器流水线中控制部件的数目

  d：PCU 控制的 ALU 或 PE 数目，d'：指令流水线中 ALU 部件的数目

  w：ALU 或 PE 的字长，w'：操作流水线中基本逻辑线路数目

- 冯氏分类法：用最大并行度$P_m$（单位时间内能够处理的最大二进制位数）分类。

  - 字串位串 WSBS：纯串行处理机
  - 字串位并 WSBP：传统单处理机
  - 字并位串 WPBS：同时处理多个字的同一位
  - 字并位并 WPBP：同时处理多个字的多个位

  平均并行度：$P_a = \frac{\sum_{i=1}^T P_i}{T}$

  T 个周期内的平均利用率：$\mu = \frac{P_a}{P_m}$

  > CRAY-1 计算机有 1 个 CPU，12 个相当于 ALU 或 PE 的处理部件，最多可以实现 8 级流水线。字长为 64 位，可以实现 1 ～ 14 位流水线处理。所以 CRAY-1 的体系结构可表示为： T(CRAY-1)=〈1×1，12×8，64×(1 ～ 14)〉。

系统结构的发展：

- 冯诺依曼结构：输入设备、输出设备、控制器、运算器、存储器。指令与数据同等对待（一条总线）。
- 哈佛结构：冯诺依曼基础上，指令与数据分离。现代计算机都是哈佛结构。

## 基本原理和性能公式

大概率事件优先原理： 优先加速使用频率高的部件。是**最重要和最广泛采用的计算机设计准则**。

程序的局部性原理：

- 时间局部性：程序即将用到的信息很可能就是目前正在使用的信息。（经验规则：程序执行时间 90%都是在执行程序中 10%的代码）
- 空间局部性：程序即将用到的信息很可能与正在使用的信息在空间上临近。

Amdahl 定律：系统性能加速比与该部件在系统中的总执行时间有关。

- $加速比S_n=\frac{改进后性能}{改进前性能}=\frac{改进前用时}{改进后用时}$

- $S_n = \frac{T_0}{T_n} = \frac{1}{(1-F_e)+\frac{F_e}{S_e}}$，$S_e$为部件加速比。

  > 某计算机系统采用浮点运算部件后，使浮点运算速度提高到原来的 25 倍，而系统运行某一程序的整体性能提高到原来的 4 倍，试计算该程序中浮点操作所占的比例。
  >
  > 由题可知： Se = 25 Sn = 4。根据加速比可得：$4=\frac{1}{(1-F_e)+\frac{F_e}{25}}$，得 Fe=78.1%

CPU 性能公式：

- CPU 时间：执行一个程序所需 CPU 时间。

  - $CPU_{时间}=IC \times CPI \times 时钟周期时间$。时钟周期时间$t = 1/f(系统时钟频率)$。
  - $CPU_{时间}=\sum\limits_{i=1}^n (CPI_i \times IC_i)$。

- CPI：一条指令的平均时钟周期数，$CPI=执行程序所需的时钟周期数 \div IC(执行程序的指令条数)$

- CPU 性能取决于三个参数：

  - t：取决于硬件实现技术和计算机组成
  - CPI：取决于计算机组成和指令系统的结构
  - IC：取决于指令系统的结构和编译技术

  > 假设 FP 指令的比例为 25%，其中，FPSQR 占全部指令的比例为 2%，FP 操作的 CPI 为 4，FPSQR 操作的 CPI 为 20 ，其他指令的平均 CPI 为 1.33。现有两种改进方案，第一种是把 FPSQR 操作的 CPI 减至 2，第二种是把所有的 FP 操作的 CPI 减至 2，比较两种方案对系统性能的提高程度。
  >
  > 解：改进前，指令的平均时钟周期 CPI 为： $4 \times 0.25 + 1.33 \times 0.75 = 2$
  >
  > 第一种方案：CPI 改进了$(20-2) \times 0.02 = 0.36$
  >
  > 第二种方案：CPI 改进了$(4-2) \times 0.25 = 0.5$
  >
  > 第二种方案的改进较大。

## 性能评价标准

评价方法：CPU 时间、<u>CPI</u>、MIPS、MFLOPS。

比较若干测试程序在不同机器上的执行时间：

- 平均执行时间：各程序执行时间的算术平均值。
- 加权执行时间：各程序执行时间的加权平均值。
- 调和平均值法：执行任务数量$\div$总耗时（速度不可简单相加）。$H_m = \frac{n}{\sum_{i=1}^n T_i}$
- 几何平均值法：执行速度的几何均值。$G_m = \sqrt[n]{\prod_{i=1}^n R_i}$

# 第三章流水线

> 流水线的基本概念及分类：静、动态流水线；单、多流水线；线性、非线性流水线
>
> 流水线表示：<u>时空图、连接图</u>
>
> <u>流水线性能计算和分析</u>：吞吐率、加速比、效率
>
> 多功能/静态动态流水线的时空图
>
> 流水线相关与冲突：
>
> - 经典五段流水线：<u>各段完成的操作</u>
>
>   - <u>数据相关（真相关）、名相关、控制相关</u>
>   - <u>结构冲突、数据冲突、控制冲突</u>
>   - 数据冲突的各种形式（RAW、WAR、WAW 等）
>
> - <u>减少数据冲突的方法：延迟、定向、编译</u>
>
> - <u>解决控制冲突的方法：排空、预测、延迟分支、编译</u>

## 流水线基本概念及分类

流水线技术主要思想是把一个复杂任务分解为若干个子任务。每个子任务由专门功能部件完成，并使多个子任务并行执行。

流水线技术的核心：部件功能专用化。（一件工作按功能分隔为若干相互联系的部分，每一部分指定给专门部件（段）完成，各部件（段）执行过程时间重叠，所有部件依次序分工完成工作。）

流水线的级：流水线中每个子过程及其功能部件，称为一个流水段。流水线的段数称为流水线深度（长度）。

- 操作部件采用流水线，称为操作部件流水线。
- 指令执行过程采用流水线，称为指令流水线。
- 访问主存部件采用流水线，称为访存部件流水线。
- 多计算机通过存储器连接构成流水线，称为宏流水线。

流水线的分类 1：

- 部件级流水线（运算操作流水线）：各类型的运算操作按流水方式进行。
- 处理级流水线（指令流水线）：把一条指令的执行过程分段，按流水方式执行。
- 系统级流水线（宏流水线）：把多台处理机串行连接起来，每个处理机完成整个任务中的一部分。

流水线的分类 2：

- 单功能流水线：只能完成固定功能。
- 多功能流水线：流水线的各段可以进行不同连接，实现不同功能。

流水线的分类 3：

- 静态流水线：同一时间内，多功能流水线中的各段只能按同一种功能的连接方式进行工作。
- 动态流水线：同一时间内，多功能流水线中的各段可以按照不同方式连接，同时执行多种功能。（而不需等到排空之后重新装入）

流水线的分类 4：

- 线性流水线：流水线各段串行连接，每个段最多流过一次。
- 非线性流水线：流水线中有反馈回路，每个段可以流过多次。

流水线的分类 5：

- 顺序流水线：流水线输出的任务顺序与输入的任务顺序相同。
- 乱序流水线：流水线输出的任务顺序与输入的顺序**可以不同**。（也称无序、错序、异步流水线）

典型的指令流水线：

- 三段：取指、分析、执行
- 四段：取指（访问主存取出指令并送到指令寄存器）、译码（形成操作数地址并读取操作数）、执行（完成指令的功能）、存结果（将运算结果写回寄存器或主存）

流水线通过时间和排空时间：

- 通过时间：第一个任务**从**进入流水线**到**流出结果所需的时间，又称装入时间

- 排空时间：最后一个任务从进入流水线到流出结果所需的时间

  在装入和排空的过程中，流水线不满载。

指令通过流水线时间最长的段称为**流水线瓶颈**。

每段流水线后面有一个**缓冲寄存器**，称为**流水寄存器**。有**缓冲、隔离、同步**作用。

## 流水线性能计算和分析

> 吞吐率、加速比、效率、最佳段数。

吞吐率 TP：单位时间内流水线完成的任务数量或输出结果的数量。$TP = \frac{n}{T}$

- 各段时间相等的流水线：理想的 k 段线性流水线完成 n 个连续任务的时间：$T_k = (k+n-1) \Delta t$

  实际吞吐率：$\frac{n}{(k+n-1) \Delta t}$

  最大吞吐率：$TP_{max}=\lim\limits_{n \to \infty} \frac{n}{(k+n-1) \Delta t} = \frac{1}{\Delta t}$

- 各段时间不等的流水线：时间最长段称为流水线的瓶颈$T_k = \sum\limits_{i=1}^k \Delta t_i + (n-1) \max (\Delta t_1,\Delta t_2,···,\Delta t_k)$

加速比 S：完成同样任务，不使用流水线所用时间与使用流水线所用时间之比。$S=\frac{T_s}{T_k}$

- 各段时间相等的 k 段流水线：$S = \frac{n \times k \Delta t}{(k+n-1) \Delta t}$

  最大加速比：k

- 各段时间不等的流水线：$S = \frac{n \sum\limits_{i=1}^k \Delta t_i}{\sum\limits_{i=1}^k \Delta t_i + (n-1) \max (\Delta t_1,\Delta t_2,···,\Delta t_k)}$

效率 E：流水线中的设备实际使用时间与整个运行时间的比值，又称流水线设备利用率。

- 连续完成 n 个任务，每段的效率计算：每段都执行了 n 个任务，用时$n \Delta t$，效率$e = \frac{n \Delta t}{(k+n-1) \Delta t}$
- 整条流水线的效率$E = \frac{e_1+e_2+...+e_k}{k}= \frac{n}{k+n-1}$

TP、S、E 关系：

- $E=P \times \Delta t$、$E = \frac{S}{k}$

解决流水线瓶颈的方法：

- 重复设置瓶颈段：让多个瓶颈流水段并行工作。
- 瓶颈段再细分：细分为多个子流水段（每个子流水段用时和非瓶颈段相同），形成超流水线。

流水线的最佳段数：流水线段数增加，吞吐率、加速比和价格均提高。

- PCR 定义为单位价格的最大吞吐率。
- $PCR = \frac{P_{max}}{C}$，其中$P_{max} = \frac{1}{\frac{t}{k}+d}$，$C = \frac{1}{a+b \times k}$。t 为非流水机器串行完成一个任务的时间，d 为锁存器延迟，a 为流水段本身价格，b 为锁存器价格。
- 对 k 求导可得 PCR 极大值，以及对应的最佳段数$k_0$。$k_0 = \sqrt{\frac{t \times a}{d \times b}}$
- 大于等于 8 段的流水线称为超流水线。

## 流水线例题

<img src="计算机系统结构.assets/image-20210616154958511.png" alt="image-20210616154958511" style="zoom: 33%;" />

解：是静态流水线，不能动态切换流水线功能。因此应算完全部加法再算乘法。

<img src="计算机系统结构.assets/image-20210616155129119.png" alt="image-20210616155129119" style="zoom: 33%;" />

## 流水线相关与冲突（五段流水线）

经典五段流水线：分为 IF、ID、EX、MEM、WB 五个周期。

- IF：以程序计数器 PC 中的内容作为地址，从存储器中取出指令并放入指令寄存器 IR。PC 指向顺序的下一条指令。
- ID：指令译码，用 IR 中的寄存器地址去访问通用寄存器组，读出所需操作数。
- EX：
  - load 和 store 指令：ALU 把指定寄存器的内容与偏移量相加，形成访存有效地址。
  - ALU 指令：ALU 对从通用寄存器组读出的数据进行运算。
  - 分支指令：ALU 把偏移量与 PC 值相加，形成转移目标的地址。同时，判断分支是否成功。
- MEM：
  - load 和 store 指令：根据有效地址从存储器读出相应数据，或把指定数据写入有效地址指向的存储单元。
  - 分支指令：如果分支成功，就把在前一个周期中计算好的转移目标地址送入 PC。分支指令执行完成。否则，不进行任何操作。
  - ALU 指令此周期不进行操作。
- WB：把结果写入通用寄存器组。对于 ALU 指令，结果来组 ALU。对于 load 指令，结果来自存储器。

相关与流水线冲突：

- 相关：两条指令之间存在某种依赖关系，以至于他们可能无法在流水线中重叠执行，或只能部分重叠。

  相关有三种类型：数据相关（真相关）、名相关、控制相关。

  - 数据相关：下述条件之一成立，则称指令之间数据相关。

    - 指令 a 使用指令 b 产生的结果。
    - 指令 a 与指令 b 数据相关，而指令 b 与指令 c 数据相关。

    第二个条件表明数据相关具有传递性。

  - 名相关：名指指令访问的寄存器或存储器的名称。两条指令使用了相同的名，但并没有数据流动关系，则称为名相关。

    - 反相关：指令 b 写的名与指令 a 读的名相同。反相关指令之间的执行顺序必须严格遵守，保证 b 读的值是正确的。
    - 输出相关：指令 b 与指令 a 写的名相同。输出相关指令的执行顺序也必须严格遵守，保证最后的结果是指令 b 写进去的。

    名相关的两条指令之间没有数据的传送，只是恰巧用了相同的名。可以通过**换名技术**（改变指令中操作数的名）消除名相关。对于寄存器操作数换名称为**寄存器换名**。寄存器换名既可以通过编译器静态实现，也可以硬件动态完成。

  - 控制相关：分支指令和其它<u>会改变 PC 值的指令</u>引起的相关。需要根据分支指令的执行结果来确定后面该执行哪个分支上的指令。

- 流水线冲突：对于具体的流水线，由于相关的存在，指令流中的下一条指令不能在指定的时钟周期开始执行。有三种类型，<u>结构冲突、数据冲突、控制冲突。</u>约定：当一条指令被暂停时，在该指令之后流出的所有指令都要被暂停，而之前流出的指令仍继续进行。

  - 结构冲突：某种指令组合因为硬件资源冲突而不能正常执行，称具有结构冲突。功能部件不是完全流水或硬件资源份数不够时发生。解决方法：插入暂停周期，或增加 Cache 等硬件资源。

  - 数据冲突：相关的指令靠得足够近，他们在流水线中的重叠执行或重新排序会改变指令读/写操作数的顺序，使结果错误，谓数据冲突。

    - 写后读冲突（RAW、WR）：对应真数据相关。
    - 写后写冲突（WAW、WW）：对应输出相关。写后写冲突仅发生在“不止一个段可以进行写操作，或指令被重新排序”的流水线中。前述五段流水线不发生 WAW 冲突。
    - 读后写冲突（WAR、RW）：对应反相关。读后写冲突仅发生在“有些指令的写结果操作被提前、有些指令的读操作被滞后，或指令被重新排序”的流水线中。前述五段流水线不发生 WAR 冲突。

    使用<u>定向技术</u>（旁路技术）减少数据冲突引起的停顿：将计算结果从其产生的地方（ALU 出口）直接送到其他指令需要它的地方（ALU 的入口），可以避免停顿。

    需要停顿的数据冲突：对于无法通过定向技术解决的数据冲突，需要设置一个“流水线互锁机制”的功能部件保证指令正确执行。其作用是检测和发现数据冲突，并使流水线停顿（stall）直至冲突消失。

    依靠编译器解决数据冲突：在编译时让编译器重新组织指令顺序来消除冲突。称为**指令调度**或**流水线调度**。

  - 控制冲突：分支指令和其它<u>会改变 PC 值的指令</u>引起的冲突。处理分支指令最简单的方法是“冻结”“排空”流水线，在 ID 段检测到分支指令时，立即暂停流水线输入，进行 EX、MEM，确定是否分支成功并计算出新的 PC 值，这样带来 3 个时钟周期的延迟。だめ。

    为了减少**分支延迟**，可以采取：① 尽早判断出（或猜测）分支转移是否成功。② 尽早计算出分支目标地址。<u>通过编译器减少分支延迟的方法：</u>

    - 预测分支失败：在检测到分支指令之后，沿分支失败的分支继续处理指令。当确定分支是失败时（预测分支失败成功），流水线正常流动。否则（预测分支失败失败），把在分支指令之后取出的指令转化为空操作，按分支目标地址重新取指执行。

    - 预测分支成功：没用。除非已知分支目标地址。

    - 延迟分支：把无论是否分支成功都必须执行的指令，紧接着分支指令执行（放入延迟槽），延迟槽中的指令替换了原本必须插入的暂停周期。绝大多数延迟槽仅容纳一条指令。

      延迟槽指令的调度方法三种：

      - 从前调度：从分支指令之前找一条指令插入延迟槽。被调度的指令必须与分支无关，适合任何情况。
      - 从目标处调度：分支成功时起作用。分支成功概率高时采用。
      - 从失败处调度：分支失败时起作用。不能从前调度时可用。

> 条件转移分支指令通常要在 MEM 段末尾才会使 PC 内容发生改变。对于 k 级流水线，需停顿 k-1 个时钟，直到 PC 中生成新地址后，才能取出下一条指令。
>
> 最坏情况：分支指令占比为 p，预测分支失败，分支转移成功的概率为 q。k 段流水线执行 n 条指令，最坏需要多停顿$pqn(k-1) \Delta t$时间。流水线最大吞吐率为$\lim\limits_{n \to \infty} \frac{n}{(k+n-1) \Delta t + pqn(k-1) \Delta t}= \frac{1}{[1+pq(k-1)] \Delta t}$。（若没有分支指令最大吞吐率为$\frac{1}{\Delta t}$）

# 第五章指令级并行及其开发

> 指令集并行基础概念
>
> 指令的动态调度技术（硬件方法）：
>
> - 乱序执行调度的概念
> - <u>记分牌算法</u>
> - <u>Tomasulo 算法</u>
> - 基于硬件的前瞻执行
>
> 动态分支预测技术：
>
> - <u>分支历史表 BHT</u>
> - <u>分支目标缓冲器 BTB</u>
>
> 多流出技术：超标量、超流水、VLIW、静态指令调度

## 指令集并行基础概念

**指令集并行（ILP）**是指令间存在的一种并行性，使计算机可以并行执行两条及以上的指令。

<u>开发 ILP 的途径：① 资源重复（重复设置多个部件同时执行多条指令）② 采用流水线技术使指令重叠并行执行。</u>

开发 ILP 的方法：分为硬件方法和软件方法。本章为硬件方法。

流水线处理机的实际 CPI：$CPI_{流水线} = CPI_{理想}+停顿_{结构冲突}+停顿_{数据冲突}+停顿_{控制冲突}$。减少停顿以提高降低 CPI、提高 IPC。

<u>基本程序块</u>：一串连续的代码除了入口和出口之外，没有其他的分支指令和转入点，称为一个**基本程序块**。

循环并行性：循环的不同迭代之间存在的并行性。本章不讨论。

相关与指令级并行（概念）：

- 程序顺序：由原来程序确定的在完全串行方式下指令的执行顺序。我们需要尽可能地开发并行性，只有在可能导致错误的情况下，才保持程序顺序。
- 保持异常行为：无论怎么改变指令的执行顺序，都不能改变程序中异常的发生情况。实际使用中：指令执行顺序的改变不导致程序中发生新的异常。
- 数据流：数据值从其产生者指令，到其消费者指令的实际流动。分支指令使得数据流有动态性，分支指令的执行结果决定哪条指令才是所需数据的产生者。 之后讨论的**前瞻执行**不仅解决异常问题，还能在保持数据流的情况下减少控制相关对开发 ILP 的影响。

## 指令的动态调度技术（硬件方法）

**静态调度**在编译期间，把相关的指令拉开距离来减少可能产生的停顿。

**动态调度**能在保持数据流和异常行为的情况下，通过硬件对指令执行顺序重排，减少数据相关导致的停顿：

- 优点：① 能处理编译时情况不明的相关（如存储器访问相关），并简化编译器。② 使同一段代码能在不同流水线上高效地执行。
- 代价：硬件复杂性显著增加。

动态调度基本思想：

- 将流水线的 ID 段分为“IS 流出”、“RO 读操作数”两个阶段。这样使得指令**乱序执行**，指令的完成也是**乱序完成**。
- 乱序执行带来新问题：
  - RW 冲突和 WW 冲突。
  - 异常处理复杂化。**不精确异常**：异常时处理机现场与严格按程序顺序执行时现场不同。不精确异常使得异常处理后难以继续执行原有程序。产生不精确异常的原因：当指令 a 导致异常发生时，流水线已经执行程序顺序是 a 之后的指令，还没完成程序顺序是 a 之前的指令。

典型动态调度算法：**记分牌算法、Tomasulo 算法**。主要考虑的因素：资源（结构）利用效率、三种数据相关。

### 记分牌算法

<u>记分牌的目标：尽早执行没有结构冲突和数据冲突的指令。</u>

指令执行的步骤：每条指令的执行过程分为 4 段——IS 流出、RO 读操作数、EX 执行、WB 写结果。（主要考虑浮点操作，运算在浮点寄存器之间进行，不涉及 MEM 段）

- 流出：若流出指令所需的功能部件空闲，并且所有其他执行中的指令的目的寄存器与该指令不同，记分牌就向功能部件流出该指令，并修改记分牌内部的记录表。如果存在结构相关或 WAW 冲突，则该指令不流出。（<u>在流出段解决了 WAW 冲突</u>）
- 读操作数：记分牌检测源操作数的可用性。一旦数据可用，它就通知功能部件从寄存器中读出源操作数并开始执行。否则就等待写完成之后再读出（锁定）（<u>读操作数段动态地解决了 RAW 冲突，并可能导致指令乱序执行</u>）
- 执行：取到操作数后，功能部件开始执行。结果产生后，通知记分牌它已完成执行。这一步相当于五段流水线中的 EX。但在浮点流水线中，<u>这一段可能占用多个时钟周期</u>。其他指令如果不与<u>正在执行或被锁定</u>指令相关，可提前执行或完成。
- 写结果：记分牌知道执行部件完成执行后，检测是否存在 WAR 冲突（前面某条指令的源操作数寄存器，是本指令的目标寄存器）。如果不存在（或已有的 WAR 冲突已消失），记分牌就通知功能部件把结果写入目的寄存器，并释放该指令执行所用的所有资源。否则必须等待。这一步对应五段流水线的 WB。

记分牌记录信息的组成：

- 指令状态表：记录正在执行的各条指令已经进入哪一段。
- 功能部件状态表：记录各个功能部件的状态。每个功能部件有 1 项，每项由 9 个字段组成。
  - Busy：忙标志，功能部件是否正忙。
  - Op：正在或将要执行的操作。
  - $F_i$：目的寄存器编号，$F_j,F_k$：源寄存器编号。（按指令中的顺序排列）
  - $Q_j,Q_k$：向源寄存器$F_j,F_k$写数据的功能部件。
  - $R_j,R_k$：源寄存器标志位，“yes”表示$F_j/F_k$的操作数**<u>可用——就绪且未被取走（产生且未读）</u>**。否则“no”。
- 结果寄存器状态表：每个寄存器在该表中有一项，用于指出哪个功能部件（编号）将把结果写入该寄存器。如果正运行的指令全都不以它为目的寄存器，则设置为“no”或 0。

<img src="计算机系统结构.assets/image-20210621175746367.png" alt="image-20210621175746367" style="zoom:50%;" />

记分牌算法的冲突分析：

- WW 冲突会导致记分牌在流出阶段停顿。

- RW 冲突会导致记分牌在写结果阶段停顿。

- 真相关引起的 WR 冲突会导致记分牌在读操作数阶段停顿。

- 资源冲突会导致记分牌在流出阶段停顿。

  通过记分牌，避免了 WW、WR、RW 冲突及结构冲突。

### Tomasulo 算法

又称公共数据总线法。通过<u>分散控制</u>，处理数据相关和乱序执行。

基于 Tomasulo 算法的 MIPS 处理器浮点部件主要结构：

- 指令队列：存放部件送来的指令，FIFO、顺序流出。
- 保留站：保存流出到本功能部件执行的指令信息（包括操作码、操作数、解决冲突的信息）。每个保留站有一个标识字段，唯一地标识了该保留站。
- 访存部件缓冲器：load 缓冲器和 store 缓冲器存放读/写存储器的数据或地址（类似保留站）。
- 公共数据总线 CDB：重要的数据通路。所有计算结果都送到 CDB，它直接播送到各个需要的地方。多个执行部件且采用多流出的流水线中有多条 CDB。计算结果先送到 CDB 再传送到功能部件，不需要经过寄存器。
- 浮点寄存器 FP：通过总线连接到各功能部件，通过 CDB 连接到 store 缓冲器。
- 运算部件：浮点加法器和浮点乘法器。

核心思想：

- 记录和检测指令相关，把发生 WR 冲突的可能性减到最小。
- 通过<u>寄存器换名</u>技术消除 RW 冲突和 WW 冲突：寄存器换名通过保留站和流出逻辑共同完成。当指令流出时，如果其操作数还没有计算出来，则将该指令中相应的寄存器号换名为将产生这个操作数的保留站的标识。当指令流出到保留站之后，其操作数寄存器号要么换成了数据本身（已就绪状态），要么换成了保留站标识，而不再与寄存器相关。这样消除了 WAR 冲突。

指令执行的步骤：三步。

- 流出：从指令队列头部取指。如果该指令操作所要求的的保留站有空闲的，则把该指令送到该空闲保留站（设为 r）。如果操作数未就绪，则进行寄存器换名。另外，进行目的寄存器预约，将其设置为接收保留站 r 的结果（相当于提前完成了写操作）。由于指令顺序流出，同一个结果寄存器的预约结果肯定是最后一条指令的，消除了 WAW 冲突。如果没有空闲保留站，指令不能留出（发生结构冲突）。
- 执行：如果某个操作数未被计算出来，保留站监视 CDB，结果产生保留站立刻从 CDB 获取数据。操作数都就绪后保留站用相应的功能部件开始执行指令操作。（靠推迟执行的方法解决 RAW 冲突）load 指令执行条件是存储器部件就绪，而 store 指令执行的条件是要存入存储器的数据到达并且存储器部件就绪。
- 写结果：功能部件计算完毕后将结果放到 CDB 上，等待该结果的寄存器和保留站同时从 CDB 获取数据。

保留站字段：

- Op：对源操作数进行的操作。
- $Q_j,Q_k$：将产生源操作数的保留站号。0 表示操作数已就绪且在$V_j/V_k$中，或者不需要操作数。
- $V_j,V_k$：源操作数的值，如`Reg[F4]​`。对于每一个操作数来说，V 或 Q 字段只有一个有效。
- Busy：“yes”表示本保留站或缓冲单元正忙。
- A：仅 load 和 store 缓冲器有该字段。开始先存放指令中的立即数字段，地址计算后存放有效地址。

![image-20210621200752388](计算机系统结构.assets/image-20210621200752388.png)

![image-20210621200740644](计算机系统结构.assets/image-20210621200740644.png)

Tomasulo 算法的优点：

- 冲突检测逻辑和指令执行控制是分布的（通过保留站和 CDB 实现）。
- 通过寄存器换名和预约，消除了 WW 冲突和 RW 冲突导致的停顿。
- 通过延迟执行解决 WR 冲突。
- 保留站、寄存器组均有附加信息，用于检测和消除冲突。

## 动态分支预测技术

开发的 ILP 越多，控制相关的制约就越大：① 在 n 流出（每个时钟周期流出 n 条指令）处理机中，遇到分支指令的可能性增加 n 倍。② 根据 Amdahl 定律，机器 CPI 越小，控制停顿的相对影响越大。

动态分支预测技术目的：① 预测分支是否成功。② 尽快找到分支目标地址或指令。

动态分支预测技术需要解决的问题：① 如何记录分支的历史信息。② 如何根据这些信息预测分支去向，甚至提前取出分支目标指令。

### 分支历史表 BHT

记录分支指令最近几次的执行情况（成功或失败），并据此预测。使用两个 bit 存储历史分支信息。

<img src="计算机系统结构.assets/image-20210621201952952.png" alt="image-20210621201952952" style="zoom:50%;" />

BHT 两个步骤：

- 分支预测：当分支指令到达 ID 时，从 BHT 读出的信息进行分支预测。若正确就继续处理后续指令。若错误就作废预取指令，恢复现场，并从另一条分支路径重新取指。
- 状态修改：修改 BHT 状态。

### 分支目标缓冲器 BTB

分支目标缓冲器 Branch-Target Buffer 作用：

- 将分支成功的分支指令的地址，和它的分支目标地址都放到一个缓冲区中保存。
- 缓冲区以分支指令的地址作为标识，得到转移目标指令地址信息。
- 在 IF 段访问 BTB，将分支的开销降为 0。

<img src="计算机系统结构.assets/image-20210621202833308.png" alt="image-20210621202833308" style="zoom: 50%;" />

<img src="计算机系统结构.assets/image-20210621202935476.png" alt="image-20210621202935476" style="zoom:50%;" />

| 指令在 BTB 中？ | 预测 | 实际情况 | 延迟周期 |
| --------------- | ---- | -------- | -------- |
| 是              | 成功 | 成功     | 0        |
| 是              | 成功 | 不成功   | 2        |
| 否              |      | 成功     | 2        |
| 否              |      | 不成功   | 0        |

（延迟两个周期：预测失败需要更新 BTB 的项，花费 1 个周期。对 BTB 项进行更改时需要停止取值，又花费 1 个周期）

### 基于硬件的前瞻执行（略）

基本思想：对分支结果预测，按预测结果继续取指、流出、执行后续指令，但结果不写回寄存区或存储器，而是写入**再定序缓冲器 ROB**，等到指令“确认”之后再写回寄存器或存储器。

前瞻执行机制下指令的执行步骤：流出——执行——写结果到 ROB——确认。

## 多流出技术

在每个时钟周期内流出多条指令，CPI<1。

<img src="计算机系统结构.assets/image-20210621204809703.png" alt="image-20210621204809703" style="zoom:50%;" />

两种多流出处理机：

- 超标量：
  - 每个时钟周期流出的指令条数<u>不固定</u>，但有上限 n。这种处理机称为 n 流出（n 发射）处理机。
  - 可以通过编译器静态调度，也可以基于 Tomasulo 算法进行动态调度。
- 超长指令字 VLIW（Very Long Instruction Word）：
  - 单一的流或控制器：在每个周期流出指令条数固定，这些指令构成一个长指令（指令包），通常大于 100 位。
  - 指令包中的指令之间并行性通过指令显式地表示出来。
  - 大量的数据通路和功能部件：设置多个功能部件。
  - 超长指令字包含多个控制字段：指令字被分割成一些字段，每个字段称为一个**操作槽**，直接独立控制一个功能部件。
  - 超长指令字的生成由编译器完成：指令调度由编译器静态完成，流出时无需复杂冲突检测。

<img src="计算机系统结构.assets/image-20210621210007044.png" alt="image-20210621210007044" style="zoom: 33%;" />

静态调度的多流出技术：

- 每个时钟周期流出 n 条指令。称为流出包。
- 指令按序流出，在流出时由流出部件进行冲突检测：
  - 第一阶段：进行流出包内的冲突检测，选出初步判定可以流出的指令。
  - 第二阶段：检测选出的指令与正在执行的指令是否冲突。

超流水线处理机：每 1/n 个时钟周期流出一条指令。

<img src="计算机系统结构.assets/image-20210621210238347.png" alt="image-20210621210238347" style="zoom: 33%;" />

# 第四章 向量流水处理机

> 向量处理方法：横向处理、纵向处理、纵横处理
>
> 向量流水处理机结构：
>
> - 存储器-存储器结构：纵向处理
> - 寄存器-寄存器结构：纵横处理
>
> 提高向量处理机性能的方法：
>
> - 多功能部件的并行操作
> - <u>链接技术 WD 相关</u>
> - 分段开采
> - 多处理机系统结构
>
> 向量处理机性能的主要参数：
>
> - 一条向量指令的处理时间
> - <u>一组向量指令的处理时间</u>
> - 向量处理机的性能评估（MFLOPS 或一个浮点运算的时间）

## 向量基本概念和处理方法

向量处理机：设置了向量数据表示和向量指令的流水线处理机。

向量处理机方式：

- 横向处理方式：向量按 column 的方式从左到右横向进行。适用于一般处理机，不适用于向量处理机的并行处理。
- 纵向处理方式：向量按 row 的方式从上到下纵向进行。将整个向量按相同运算处理完之后，再进行别的运算。不产生数据相关，对向量长度 N 没有限制。
- 纵横处理方式：把向量分成若干组，组内按纵向方式处理，依次处理各组。对向量长度 N 没有限制，但以每 n 个元素分一组处理，n 的值固定。

## 向量处理机结构

存储器-存储器结构：适合纵向处理方式。

- 源向量和目的向量都存放在存储器中，运算的中间结果需要送回存储器。
- 对应的向量分量能并发访问，计算结果能并行地保存。
- 普通存储器的 3 倍带宽：一个时钟周期内读出两个操作数并写回一个结果。

寄存器-寄存器结构：适合纵横处理方式。

-

# 第九章 互连网络

> <u>互连函数</u>
>
> <u>互连网络的结构参数与性能指标</u>
>
> <u>静态互联网络</u>
>
> 动态互联网络
>
> 消息传递机制

# 第十三章 阵列处理机

> 阵列处理机概念
>
> 阵列处理机的结构：
>
> - 分布式存储器的阵列机
> - 共享存储器的阵列机
>
> 阵列处理机的特点（与流水线向量对比）
>
> 了解 ILLIAC IV 和 BSP 阵列处理器基本结构
>
> 典型算法：
>
> - <u>递归折叠求和算法</u>

# 第十章 多处理机

> 多处理机概念：
>
> - <u>MIMD 计算机的特点、分类</u>：PVP/SMP/MPP/DSM/COW
>
> 对称式共享存储器多处理器（SMP）系统结构及特点
>
> 分布式共享存储器多处理器系统结构及特点：
>
> - Cache 一致性问题成因和解决方法（写作废、写更新）
> - <u>监听协议法</u>
> - <u>目录表协议（三种结构）</u>
